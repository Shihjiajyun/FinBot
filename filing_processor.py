#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FinBot è²¡å ±è™•ç†æ¨¡çµ„
ç”¨æ–¼è§£æå’Œè™•ç† SEC EDGAR è²¡å ±æ–‡ä»¶
"""

import os
import re
import sys
import json
import mysql.connector
from pathlib import Path
from datetime import datetime
from secedgar import filings, FilingType
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET

# è³‡æ–™åº«é…ç½®
DB_CONFIG = {
    'host': '43.207.210.147',
    'database': 'finbot_db',
    'user': 'myuser',
    'password': '123456789',
    'charset': 'utf8mb4'
}

# è²¡å ±é¡å‹æ˜ å°„
FILING_TYPE_MAP = {
    "10-K": FilingType.FILING_10K,
    "10-Q": FilingType.FILING_10Q,
    "8-K": FilingType.FILING_8K,
    "4": FilingType.FILING_4,
    "13F-HR": FilingType.FILING_13FHR
}

class FilingProcessor:
    def __init__(self):
        self.db_connection = None
        self.connect_db()
        
    def connect_db(self):
        """é€£æ¥è³‡æ–™åº«"""
        try:
            self.db_connection = mysql.connector.connect(**DB_CONFIG)
            print("âœ… è³‡æ–™åº«é€£æ¥æˆåŠŸ")
        except mysql.connector.Error as err:
            print(f"âŒ è³‡æ–™åº«é€£æ¥å¤±æ•—: {err}")
            sys.exit(1)
    
    def extract_filing_metadata(self, file_path):
        """å¾è²¡å ±æ–‡ä»¶ä¸­æå–å…ƒæ•¸æ“š"""
        result = {}
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(10000)  # åªè®€å‰10000å€‹å­—ç¬¦
                
                # æå–å„ç¨®å…ƒæ•¸æ“š - ä¿®æ­£æ­£å‰‡è¡¨é”å¼æ¨¡å¼
                patterns = {
                    'accession_number': r'ACCESSION NUMBER:\s*(.+)',
                    'filing_type': r'CONFORMED SUBMISSION TYPE:\s*(.+)',
                    'report_date': r'CONFORMED PERIOD OF REPORT:\s*(\d{8})',
                    'filed_date': r'FILED AS OF DATE:\s*(\d{8})',
                    'company_name': r'COMPANY CONFORMED NAME:\s*(.+)',
                    'cik': r'CENTRAL INDEX KEY:\s*(\d+)'
                }
                
                for key, pattern in patterns.items():
                    match = re.search(pattern, content, re.IGNORECASE)
                    if match:
                        value = match.group(1).strip()
                        if key in ['report_date', 'filed_date'] and len(value) == 8:
                            # è½‰æ›æ—¥æœŸæ ¼å¼ YYYYMMDD -> YYYY-MM-DD
                            value = f"{value[:4]}-{value[4:6]}-{value[6:8]}"
                        result[key] = value
                
                # å¾æª”æ¡ˆåç¨±ä¸­æå–å¹´ä»½ (ä¾‹å¦‚: 0000320193-17-000003.txt -> 2017)
                filename = Path(file_path).name
                year_match = re.search(r'-(\d{2})-', filename)
                if year_match:
                    year_suffix = int(year_match.group(1))
                    # å‡è¨­17-99æ˜¯20xxå¹´ï¼Œ00-16æ˜¯20xxå¹´
                    if year_suffix >= 17:
                        result['filing_year'] = 2000 + year_suffix
                    else:
                        result['filing_year'] = 2000 + year_suffix
                        
        except Exception as e:
            print(f"âŒ è§£ææ–‡ä»¶å…ƒæ•¸æ“šå¤±æ•— {file_path}: {e}")
            
        return result
    
    def extract_form4_tables(self, content):
        """æå–Form 4çš„äº¤æ˜“è¡¨æ ¼"""
        tables = {}
        
        try:
            # æå– nonDerivativeTable
            non_derivative_pattern = r'<nonDerivativeTable>(.*?)</nonDerivativeTable>'
            non_derivative_match = re.search(non_derivative_pattern, content, re.DOTALL | re.IGNORECASE)
            if non_derivative_match:
                tables['non_derivative_table'] = non_derivative_match.group(1).strip()
            
            # æå– derivativeTable
            derivative_pattern = r'<derivativeTable>(.*?)</derivativeTable>'
            derivative_match = re.search(derivative_pattern, content, re.DOTALL | re.IGNORECASE)
            if derivative_match:
                tables['derivative_table'] = derivative_match.group(1).strip()
                        
        except Exception as e:
            print(f"âš ï¸ Form 4è¡¨æ ¼æå–è­¦å‘Š: {e}")
            
        return tables
    
    def extract_10k_items(self, content):
        """æå–10Kè²¡å ±çš„ç‰¹å®šItems"""
        items = {}
        
        try:
            # å®šç¾©è¦æŠ“å–çš„ItemsåŠå…¶é †åº
            target_items = [
                ('item_1', r'Item&#160;1\.'),
                ('item_1a', r'Item&#160;1A\.'),
                ('item_2', r'Item&#160;2\.'),
                ('item_7', r'Item&#160;7\.'),
                ('item_7a', r'Item&#160;7A\.'),
                ('item_8', r'Item&#160;8\.')
            ]
            
            # å®Œæ•´çš„Itemsé †åºç”¨æ–¼ç¢ºå®šçµæŸé»
            all_items_pattern = [
                r'Item&#160;1\.',
                r'Item&#160;1A\.',
                r'Item&#160;1B\.',
                r'Item&#160;1C\.',
                r'Item&#160;2\.',
                r'Item&#160;3\.',
                r'Item&#160;4\.',
                r'Item&#160;7\.',
                r'Item&#160;7A\.',
                r'Item&#160;8\.',
                r'Item&#160;9\.',
                r'Item&#160;9A\.',
                r'Item&#160;9B\.',
                r'Item&#160;9C\.'
            ]
            
            for item_key, item_pattern in target_items:
                print(f"   ğŸ” æœå°‹ {item_key}...")
                
                # æ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„ä½ç½®
                matches = list(re.finditer(item_pattern, content, re.IGNORECASE))
                
                if matches:
                    # å¦‚æœæ‰¾åˆ°å¤šå€‹ï¼Œä½¿ç”¨æœ€å¾Œä¸€å€‹
                    start_match = matches[-1]
                    start_pos = start_match.end()
                    
                    # æ‰¾åˆ°ä¸‹ä¸€å€‹Itemçš„ä½ç½®ä½œç‚ºçµæŸé»
                    end_pos = len(content)
                    current_item_index = None
                    
                    # æ‰¾åˆ°ç•¶å‰itemåœ¨å®Œæ•´åˆ—è¡¨ä¸­çš„ä½ç½®
                    for i, pattern in enumerate(all_items_pattern):
                        if pattern == item_pattern:
                            current_item_index = i
                            break
                    
                    if current_item_index is not None:
                        # æœå°‹å¾ŒçºŒçš„Itemsä½œç‚ºçµæŸé»
                        for next_pattern in all_items_pattern[current_item_index + 1:]:
                            next_matches = list(re.finditer(next_pattern, content[start_pos:], re.IGNORECASE))
                            if next_matches:
                                end_pos = start_pos + next_matches[0].start()
                        break
            
                    # æå–å…§å®¹
                    extracted_content = content[start_pos:end_pos].strip()
                    
                    # é™åˆ¶é•·åº¦ä¸¦æ¸…ç†å…§å®¹
                    if len(extracted_content) > 100000:  # é™åˆ¶é•·åº¦
                        extracted_content = extracted_content[:100000] + "... [å…§å®¹éé•·ï¼Œå·²æˆªæ–·]"
                    
                    # ç§»é™¤éå¤šçš„ç©ºç™½å­—ç¬¦
                    extracted_content = re.sub(r'\s+', ' ', extracted_content)
                    
                    items[item_key + '_content'] = extracted_content
                    print(f"   âœ… æˆåŠŸæå– {item_key}: {len(extracted_content)} å­—ç¬¦")
                else:
                    print(f"   âš ï¸ æœªæ‰¾åˆ° {item_key}")
                
        except Exception as e:
            print(f"âš ï¸ 10K Itemsæå–è­¦å‘Š: {e}")
            
        return items
    
    def process_filing_file(self, file_path):
        """è™•ç†å–®å€‹è²¡å ±æ–‡ä»¶"""
        print(f"ğŸ“„ è™•ç†æ–‡ä»¶: {file_path}")
        
        # æå–å…ƒæ•¸æ“š
        metadata = self.extract_filing_metadata(file_path)
        if not metadata.get('accession_number'):
            print(f"âš ï¸ è·³éæ–‡ä»¶ï¼ˆç„¡æ³•æå–å…ƒæ•¸æ“šï¼‰: {file_path}")
            return False
        
        # è·³éä¸è™•ç†çš„æ–‡ä»¶é¡å‹
        filing_type = metadata.get('filing_type', '')
        if filing_type in ['13F-HR', '10-Q', '8-K']:
            print(f"âš ï¸ è·³éæ–‡ä»¶é¡å‹ {filing_type}: {file_path}")
            return False
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        cursor = self.db_connection.cursor()
        cursor.execute("SELECT id FROM filings WHERE accession_number = %s", 
                      (metadata['accession_number'],))
        if cursor.fetchone():
            print(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³é: {metadata['accession_number']}")
            cursor.close()
            return False
        
        # è®€å–å®Œæ•´å…§å®¹
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
        except Exception as e:
            print(f"âŒ è®€å–æ–‡ä»¶å…§å®¹å¤±æ•—: {e}")
            cursor.close()
            return False
        
        # æ ¹æ“šæ–‡ä»¶é¡å‹æå–ä¸åŒå…§å®¹
        extracted_data = {}
        
        if filing_type == '4':
            # Form 4 - æå–äº¤æ˜“è¡¨æ ¼
            print(f"   ğŸ“Š è™•ç†Form 4äº¤æ˜“æ•¸æ“š...")
            tables = self.extract_form4_tables(content)
            extracted_data.update(tables)
            
        elif filing_type == '10-K':
            # 10-K - æå–ç‰¹å®šItems
            print(f"   ğŸ“‹ è™•ç†10-K Items...")
            items = self.extract_10k_items(content)
            extracted_data.update(items)
        
        # æ’å…¥è³‡æ–™åº«
        try:
            file_url = self.generate_file_url(str(file_path))
            
            sql = """
            INSERT INTO filings (
                cik, company_name, filing_type, filing_year, accession_number, 
                report_date, filed_date, filepath, file_url, content_summary,
                item_1_content, item_1a_content, item_2_content, 
                item_7_content, item_7a_content, item_8_content,
                non_derivative_table, derivative_table
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            
            values = (
                metadata.get('cik', ''),
                metadata.get('company_name', ''),
                metadata.get('filing_type', ''),
                metadata.get('filing_year'),
                metadata.get('accession_number', ''),
                metadata.get('report_date'),
                metadata.get('filed_date'),
                str(file_path),
                file_url,
                f"å…¬å¸: {metadata.get('company_name', '')}, é¡å‹: {metadata.get('filing_type', '')}, å¹´ä»½: {metadata.get('filing_year', 'N/A')}",
                # 10K Items
                extracted_data.get('item_1_content', ''),
                extracted_data.get('item_1a_content', ''),
                extracted_data.get('item_2_content', ''),
                extracted_data.get('item_7_content', ''),
                extracted_data.get('item_7a_content', ''),
                extracted_data.get('item_8_content', ''),
                # Form 4 Tables
                extracted_data.get('non_derivative_table', ''),
                extracted_data.get('derivative_table', '')
            )
            
            cursor.execute(sql, values)
            self.db_connection.commit()
            print(f"âœ… æˆåŠŸä¿å­˜: {metadata['company_name']} - {metadata['filing_type']}")
            cursor.close()
            return True
            
        except mysql.connector.Error as err:
            print(f"âŒ è³‡æ–™åº«æ’å…¥å¤±æ•—: {err}")
            cursor.close()
            return False
    
    def process_amzn_directory(self, downloads_path="./downloads"):
        """åªè™•ç†AMZNè³‡æ–™å¤¾"""
        downloads_path = Path(downloads_path)
        amzn_path = downloads_path / "AMZN"
        
        if not amzn_path.exists():
            print(f"âŒ AMZNç›®éŒ„ä¸å­˜åœ¨: {amzn_path}")
            return
        
        print(f"ğŸ” æƒæAMZNç›®éŒ„: {amzn_path}")
        
        # åªè™•ç†Form 4å’Œ10-Kæ–‡ä»¶
        target_folders = ["4", "10-K"]
        processed = 0
        
        for folder in target_folders:
            folder_path = amzn_path / folder
            if folder_path.exists():
                print(f"\nğŸ“ è™•ç† {folder} è³‡æ–™å¤¾...")
                txt_files = list(folder_path.glob("*.txt"))
                print(f"   ğŸ“Š æ‰¾åˆ° {len(txt_files)} å€‹æ–‡ä»¶")
                
        for file_path in txt_files:
            if self.process_filing_file(file_path):
                processed += 1
            else:
                print(f"âš ï¸ è³‡æ–™å¤¾ä¸å­˜åœ¨: {folder_path}")
                
        print(f"ğŸ‰ è™•ç†å®Œæˆ! æˆåŠŸè™•ç† {processed} å€‹æ–‡ä»¶")
    
    def close(self):
        """é—œé–‰è³‡æ–™åº«é€£æ¥"""
        if self.db_connection:
            self.db_connection.close()

    def generate_file_url(self, filepath):
        """ç”Ÿæˆæ–‡ä»¶çš„URL"""
        # å°‡æœ¬åœ°è·¯å¾‘è½‰æ›ç‚ºWeb URL
        web_path = filepath.replace('\\', '/')
        if 'downloads/' in web_path:
            # ç¢ºä¿åŒ…å« downloads/ å‰ç¶´
            if not web_path.startswith('downloads/'):
                web_path = 'downloads/' + web_path.split('downloads/')[-1]
        return f"https://shinbwei.com/FinBot/{web_path}"

def main():
    """ä¸»å‡½æ•¸ - å¯ä»¥é€šéå‘½ä»¤è¡Œèª¿ç”¨"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("python filing_processor.py process           # è™•ç†AMZNè³‡æ–™å¤¾çš„è²¡å ±æ–‡ä»¶")
        return
    
    processor = FilingProcessor()
    
    try:
        command = sys.argv[1]
        
        if command == "process":
            # è™•ç†AMZNè³‡æ–™å¤¾çš„æ–‡ä»¶
            processor.process_amzn_directory()
        else:
            print("âŒ ç„¡æ•ˆçš„å‘½ä»¤ï¼Œè«‹ä½¿ç”¨ 'process'")
            
    finally:
        processor.close()

if __name__ == "__main__":
    main() 